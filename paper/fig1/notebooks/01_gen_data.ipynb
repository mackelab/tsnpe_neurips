{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4d6c5e-2674-47bc-9449-c81ff76df6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.utils import BoxUniform\n",
    "import torch\n",
    "from sbi.inference import SNPE\n",
    "from sbi.analysis import pairplot\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import ones\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "from sbi.utils.support_posterior import PosteriorSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1735cf10-6263-46fd-9ebc-6068f652c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sim(theta):\n",
    "    return theta**2 + torch.randn(theta.shape)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0405daba-b2b3-4502-8cf8-3f796edc68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = BoxUniform(-2*ones(1), -1*ones(1))\n",
    "p2 = BoxUniform(ones(1), 2*ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65fa3c96-b946-48cd-a388-a10a8a32b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedPrior(BoxUniform):\n",
    "    def __init__(self, p1, p2):\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "    def sample(self, num_samples):\n",
    "        s = num_samples[0] / 2\n",
    "        s1 = self.p1.sample((int(s),))\n",
    "        s2 = self.p2.sample((int(s),))\n",
    "        cated = torch.cat([s1, s2])\n",
    "        r = torch.randperm(cated.size()[0])\n",
    "        return cated[r]\n",
    "    def log_prob(self, theta):\n",
    "        p1 = torch.exp(self.p1.log_prob(theta))\n",
    "        p2 = torch.exp(self.p2.log_prob(theta))\n",
    "        return torch.log(0.5 * p1 + 0.5 * p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71536cd4-17f3-41e0-86d6-ff2ad75022c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = SharedPrior(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0083c9-1133-4bda-b74c-5683437fe3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_low = -2.5\n",
    "grid_high = 2.5\n",
    "def eval_likelihood(theta, x):\n",
    "    mean = theta**2\n",
    "    dist = torch.distributions.Normal(mean, 0.2)\n",
    "    return dist.log_prob(x)\n",
    "def eval_prior(theta):\n",
    "    return prior.log_prob(theta.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a142e82-e309-4609-8cdc-ed3f7233bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xo = torch.tensor([1.2])\n",
    "resolution = 500\n",
    "def posterior_eval(theta):\n",
    "    ll = eval_likelihood(theta, xo)\n",
    "    pl = eval_prior(theta)\n",
    "    joint = ll + pl\n",
    "    joint_exp = torch.exp(joint)\n",
    "    integral = torch.sum(joint_exp) / resolution * (grid_high - grid_low)\n",
    "    posterior = joint_exp / integral\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e54fcebe-a3b5-4944-aba7-cfcdfb70f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_range = torch.linspace(grid_low, grid_high, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b7a4e0-9383-4023-bc8c-b642648f0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = posterior_eval(theta_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "161b4f85-c550-40c4-a4dd-2dbdb3550835",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = eval_prior(theta_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb59a467-1c3e-4abe-976d-9913c6eed372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x80 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mpl.rc_context(fname=\"../../.matplotlibrc\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 0.8))\n",
    "    _ = ax.plot(theta_range.numpy(), post.numpy(), c=\"k\")\n",
    "    _ = ax.plot(theta_range.numpy(), torch.exp(prior_probs).numpy(), c=\"gray\")\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    plt.savefig(\"../svg/panel_a.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "ecc442eb-b912-49be-ba85-f6a65de9b133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 116 epochs."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/tsnpe_collection/sbi/sbi/utils/sbiutils.py:591: UserWarning: The passed prior has no support property, transform will be\n",
      "                constructed from mean and std. If the passed prior is supposed to be\n",
      "                bounded consider implementing the prior.support property.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb009edba5364e95b6a0e3778b199258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 27 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706f47c2c4ab466a9de31c312a4156e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 38 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386adde1d0d54df489e40cbb6e5741ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 25 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a82466d7be49db81f54f9493385efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 27 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4e73c7b7e14e5da5d9b1b12bae094a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 39 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c76d21fa4db41ea80fe7a24019551e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 56 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3146902e219a4c698ec3f0a28543cb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 25 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dbd8889b46445ead8009ce0f87bc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 32 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3334f5864046d29e5f459d52c95571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 500 posterior samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 21 epochs."
     ]
    }
   ],
   "source": [
    "_ = torch.manual_seed(1)\n",
    "inference = SNPE(prior, density_estimator=\"nsf\")\n",
    "proposal = prior\n",
    "for _ in range(10):\n",
    "\n",
    "    theta = proposal.sample((500,))\n",
    "    x = my_sim(theta)\n",
    "\n",
    "    _ = inference.append_simulations(theta, x, proposal=proposal).train()\n",
    "    posterior = inference.build_posterior().set_default_x(torch.tensor([[1.2]]))\n",
    "    proposal = posterior\n",
    "    net = posterior.posterior_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "87057840-59c3-475d-bbbe-ee72a91d2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../results/fig6_apt_posterior_10rounds_seed1.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "3469c595-2a2e-421c-b08d-47050e8ad7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../results/fig6_apt_posterior_10rounds_seed1.pkl\", \"rb\") as handle:\n",
    "    posterior = pickle.load(handle)\n",
    "net_apt = posterior.posterior_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "4cc43962-3696-48ad-a3ab-8eaeadb59910",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_probs = net_apt.log_prob(theta_range.unsqueeze(1), context=torch.tensor([[1.2]]).repeat((resolution,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "db8d3bde-ec3d-48f2-b8f4-4d2b1a5190bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x80 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mpl.rc_context(fname=\"../../.matplotlibrc\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 0.8))\n",
    "    _ = ax.plot(theta_range.numpy(), torch.exp(apt_probs.detach()).numpy(), c=\"k\")\n",
    "    # _ = ax.plot(theta_range.numpy(), torch.exp(prior_probs).numpy())\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    plt.savefig(\"../svg/panel_b1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec71d8ad-17d5-4e8e-8843-92c47be42a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../results/fig6_apt_posterior.pkl\", \"rb\") as handle:\n",
    "    posterior = pickle.load(handle)\n",
    "net_apt = posterior.posterior_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c780af28-5022-4747-8c57-98ae2d21fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "apt_probs = net_apt.log_prob(theta_range.unsqueeze(1), context=torch.tensor([[1.2]]).repeat((resolution,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7a1254-060d-4ac4-a3d7-524aa1f96644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAABRCAYAAACkCvYcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAADbklEQVR4nO3av0tqcRzG8ed7FEHSM4UOFk5GS9Ho5FJ/QUNjf0m0RFCDDU7VFEF/Q3PUEkFz0CYF/UIwjqal53OXeyW5vyLTcx/v84Iveg6pn3N4eyzJmZlBhJAX9QAin6V4hZbiFVqKV2gpXqGleIWW4hVaildoKV6hpXiFluIdgsvLSywuLuLi4iLqUcaa0/82fL10Oo0gCOB5HrrdbtTjjC3FOwTOud59nd7h0a8NQkvxCi3FK7QUr9BSvEJL8QotxSu0FK/QUrxCS/EKLcUrtBSv0FK8QkvxCi3FK7QUr9BSvEJL8QotxSu0FK/QUrxCS/EKLcUrtBSv0FK8QkvxCi3FK7QUr9BSvEJL8QotxSu0FK/QUrxCS/EKLcUrtBSv0FK8QkvxCi3FK7QUr9BSvEJL8QotxSu0FK/QUrxCS/EKLcUrtBSv0FK8QkvxCq2xj/f6+hqnp6dot9tRjzISzWYT5+fnqFarUY8ydGMZb7PZxPb2Nubn5zEzM4NSqYRCoYDDw0N0Op2oxxuKVquFcrmMqakpFItF5PN5LC0t4fj4GGYW9XjDYWPk+fnZDg4OLJ/PGwADYPF43Hzf723ncjlbW1uzs7Mzq9VqFobhl8/x47VGcXrv7+9td3e375gnJyfNOdfbnpubs729PatWq0OfZ5Sc2WBvy9nZWZhZb31/Q3x4+ysf02g0EIYhAGB6ehrr6+tYXl5GMplEpVJBuVzG4+Nj3/zxeBzJZBKJRAKJRAKxWOzT5yIMQ9TrdTQajd6+TCaDiYkJOOcA4K+3YRj+cnW73V/uC4Kg91q5XA4bGxtYXV3Fzc0NKpUK9vf3+34mlUrB933EYjF4ngfP83r3f8wwKldXV4M9waD1491V5l9YhULBNjc3LQiCn2ZttVp2dHRkKysrlslkhjaD53kjO17nnC0sLNjOzo41Go2fjrlWq9nW1pYVi8WRzvWRNaiBr7wnJydwzvUtAJHsS6VSyGazH5693W7j6ekJLy8veH19xdvbGzqdzkBXIN/3kclk4Ps+bm9v8fDw0Ptj0d59Yvzu9v0V8U8rFovBOYdsNot0Ov2h2YIgwN3dHer1Osys72re7XY/fcyfVSqVBnr8wPGKRGUsv22Q/4PiFVqKV2gpXqGleIWW4hVaildoKV6hpXiFluIVWt8Af03mG/2ri44AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 200x80 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mpl.rc_context(fname=\"../../.matplotlibrc\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 0.8))\n",
    "    _ = ax.plot(theta_range.numpy(), torch.exp(apt_probs.detach()).numpy(), c=\"k\")\n",
    "    # _ = ax.plot(theta_range.numpy(), torch.exp(prior_probs).numpy())\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    plt.savefig(\"../svg/panel_b2.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "e7b719aa-6c3e-4b0e-a329-49dbc24bad9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 116 epochs."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/tsnpe_collection/sbi/sbi/utils/sbiutils.py:591: UserWarning: The passed prior has no support property, transform will be\n",
      "                constructed from mean and std. If the passed prior is supposed to be\n",
      "                bounded consider implementing the prior.support property.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e697525147df4ce09e38ee68ed205b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 30.4300% of all samples. You will get a speed-up of 43.7%.\n",
      " Neural network successfully converged after 58 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c02cb55eca40d1b01c0b078284e9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 19.7000% of all samples. You will get a speed-up of 24.5%.\n",
      " Neural network successfully converged after 47 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f7e45e5e6843ba8d42eca477f68c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 35.0800% of all samples. You will get a speed-up of 54.0%.\n",
      " Neural network successfully converged after 65 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5814b05e1e4fbfb5f98f5055d7446f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 53.2600% of all samples. You will get a speed-up of 113.9%.\n",
      " Neural network successfully converged after 31 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a6ef1bd14b40b083e3c4a9f9603a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 55.4200% of all samples. You will get a speed-up of 124.3%.\n",
      " Neural network successfully converged after 40 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696cc6a9987645f5a1802ea8f851f312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 59.0900% of all samples. You will get a speed-up of 144.4%.\n",
      " Neural network successfully converged after 36 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800bd4a527444dc884b081a63e9f4438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 57.6200% of all samples. You will get a speed-up of 136.0%.\n",
      " Neural network successfully converged after 60 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0663124a368743cfae159288aa57167e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 53.1100% of all samples. You will get a speed-up of 113.3%.\n",
      " Neural network successfully converged after 31 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b3533a2df74dcb8f67f3de836d2842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier rejected 52.2900% of all samples. You will get a speed-up of 109.6%.\n",
      " Neural network successfully converged after 21 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c00a003d44c4133b6b7fe4267555b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = torch.manual_seed(1)\n",
    "inference = SNPE(prior, density_estimator=\"nsf\")\n",
    "proposal = prior\n",
    "for _ in range(10):\n",
    "\n",
    "    theta = proposal.sample((500,))\n",
    "    x = my_sim(theta)\n",
    "\n",
    "    _ = inference.append_simulations(theta, x).train(force_first_round_loss=True)\n",
    "    posterior = inference.build_posterior().set_default_x(torch.tensor([[1.2]]))\n",
    "    proposal = PosteriorSupport(prior=prior, posterior=posterior, allowed_false_negatives=0.0001)\n",
    "    net_tsnpe = posterior.posterior_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "aa17185a-0e6a-48fc-915d-055511f4173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../results/fig6_tsnpe_posterior_10k.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "22153e19-305c-4184-ad5e-7681aaeaa664",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../results/fig6_tsnpe_posterior_10k.pkl\", \"rb\") as handle:\n",
    "    posterior = pickle.load(handle)\n",
    "net_tsnpe = posterior.posterior_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b79a4e3f-3e46-4f1e-9154-711b8681233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsnpe_probs = net_tsnpe.log_prob(theta_range.unsqueeze(1), context=torch.tensor([[1.2]]).repeat((resolution,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "2b461231-fe75-424d-82a7-b374876d3bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAABRCAYAAACkCvYcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAG8UlEQVR4nO2dy27TWhRAl92kpAnQkMaFCop4lNcAwYAJEuI5YcAEMUECxA8wY8YI9ROQ+ANAYoDED4AERaqYgMRTQIHwKrS0obya0CT2HeQe10nT9va2tvH2WZJVJ07bnXhlax/7PAzHcRw0mghihh2ARvN/0fJqIouWVxNZtLyayKLl1UQWLa8msmh5NZFFy6uJLFpeTWTR8moii2h5JycnOXnyJOfOnaNWq4UdjmaJSYQdgJ9cu3aN69evA3D06FGOHTsWckSapUR05h0YGHD37927F2IkGj8QLe+zZ8/c/RcvXoQYSTA4jsPp06c5ceJELMokQ3KXyO7ubr5+/QrAjh07GmSWSLFYpKurC4Bbt25x+PDhkCPyF7GZt1QqueICDA0NUa1WQ4zIf8bGxtz9+/fvhxhJMIiV9/379wCk02lM06RSqTA6OhpyVP4yPj7u7l+4cIEbN26EGI3/iJd348aNrFmzBoDPnz+HGZLveOUFOH/+fEiRBINYeb98+QJAT08PPT09gHx5f//+3fB4xYoVIUUSDGKv86p617IsUqkUAMPDw2GG5DvlcrnhcbPM0hArr2q8WJblZiDpmbdZXukNVLHyqsybz+fda55xk9e27ZAiCQax8noz79TUFADfvn0LMyTfaZa3WCziOA6GYYQUkb+IbbApefP5PNlsFoCJiYnwAgqAUqk04/Hly5dDisZ/xMrrbbDFRd7mzAvQ398fQiTBIL5syOfzmGb9OxpHeRMJsadYZuat1WoUi0WgMfPGpebt7++nUCgA03WvRETK6z1huVyuoWyQeiJhWt5UKkU+nwfgz58/Yq/3ipRX1bu5XI5EIsGqVasAqFQqMxo1kvDKm8lk6OjoAGjooCQJ0fJalgVAJpOhra0NkF06eOUF3Ozr7W0miVjIaxgGK1euBODHjx+hxeU3Wl4BqK6PSl6YbnVLHmGg5RVAc+YF3LJBsryqnm+WV9e8ESKu8jZnXtVQlVrna3kFoeUVwKdPnwDcERSg5ZWISHnVMPetW7e6z8VJXnV9N5fLAVreyFAqldzW9aZNm9zn4ySvzrwRRdW7yWTSvbYLWl6JiJXXsqyGTtjS5bVt2+10r+WNKN4RFF6ky+vtDtlKXokdksTJ6x275iXO8lYqFSYnJ0OJy0/EyRv3zNvW1ubeCs9kMu6+xNJBnLxxz7wq60K9Q5LkulecvHHNvM39GhRKXjWyRBLi5G11axjiI286nW54vru7G5ie/koSYuWNW9mgGmTN8m7YsAGAd+/eBR2S74iTN65lw3zyqgGZkhAnb1wzryobVL8GhZY3IjQPefciXd75Mu/bt2+DDsl3RMnrHfKu1mZQxF3eQqEg7i6bKHnV2DU15N2LmjUnbvL29vZiGAblcpmRkZEwQvMNUfKqk7N69eoZx+Kaedvb29m8eTMAT548CTwuP9HyCmE2eQF27doFwOPHjwONyW+0vEKY7WoDwJYtWwB4/fp1oDH5TWzkbW9vB+o9rCQyV+bt6+sD6mvRSSI28qqMJHWusrnkVTWvzrx/MWrNCS1vI0reQqEgapEVUfK+efMGqC8c2Eyc5V27di3Lli2jWq26iytKQIy8tVrNvYukMo0X1VWw1ezhEvj16xfQWl7TNN2R1JJKBzHyfvz4kUqlQjKZZN26dTOOS8+8379/B6b77zajvtCSGm1i5H358iVQvx2qLot5kS6vGimhZoFvRl1x0Jn3L2RwcBCAPXv2tDwuXV61WMxs8urM+xczMDAAwL59+1oeVydV4ly1tVrNnTS7s7Oz5WtU5n369GlgcfmNCHk/fPjA7du3AThy5EjL10jMPIqxsTF3pcvmfsyKvXv3kkgkGBoa4tWrVwFH6A+RlrdcLvPgwQNOnTqFbdscOnSIbdu2tXxtX18fyWSS8fFxbt68Keo2sRqfZlnWrOuudXZ2cvDgQQAuXrwoonwynEV28ty+fTuO47TcgFmPLcVxdXkI6nMUDA4OsnPnzlljPXPmDFeuXAHqfR2y2aw7z4H3p99r9bZ6L7Ztz/le59pUvbt7924ePnw46/+9e/cuBw4ccN+/ZVl0dHRgGAamaWKaJoZhBLZW8fPnzxf3B5xFAoS6LV++3Dl+/Ljz6NGjeWP9+fOnc/bsWSeVSoUetx/bpUuX5v0Mrl696qxfvz70WJdAPWfRmffOnTvut7XVBvh2PJvN0tXVteBMUa1WGRkZYWJiglqt5m7VanXB5cRCPz7n39rUu3kz3v/d0uk0vb29/zmG4eFhRkdHmZqawrZtN/Pbtr2g97MY9u/fv6jfX7S8Gk1YRLrBpok3Wl5NZNHyaiKLllcTWbS8msii5dVEFi2vJrJoeTWRRcuriSxaXk1k+QdwByMOjbqAeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 200x80 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mpl.rc_context(fname=\"../../.matplotlibrc\"):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 0.8))\n",
    "    _ = ax.plot(theta_range.numpy(), torch.exp(tsnpe_probs.detach()).numpy(), c=\"k\")\n",
    "    # _ = ax.plot(theta_range.numpy(), torch.exp(prior_probs).numpy())\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    plt.savefig(\"../svg/panel_c.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395de4eb-0797-48dc-ac2a-76264e714c32",
   "metadata": {},
   "source": [
    "# Assemble figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af24972-7a71-4fb4-be1b-d2119a51376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import IPython.display as IPd\n",
    "\n",
    "def svg(img):\n",
    "    IPd.display(IPd.HTML('<img src=\"{}\" / >'.format(img, time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c74264-74df-42dd-a092-312f49290f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../fig/fig6.svg\" / >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from svgutils.compose import *\n",
    "\n",
    "# > Inkscape pixel is 1/90 of an inch, other software usually uses 1/72.\n",
    "# > http://www.inkscapeforum.com/viewtopic.php?f=6&t=5964\n",
    "svg_scale = 1.25  # set this to 1.25 for Inkscape, 1.0 otherwise\n",
    "\n",
    "# Panel letters in Helvetica Neue, 12pt, Medium\n",
    "kwargs_text = {'size': '12pt', 'font': 'Arial', 'weight': '800'}\n",
    "kwargs_consistent = {'size': '10pt', 'font': 'Arial', 'weight': '500', 'color': '#AF99EF'}\n",
    "kwargs_consistent1 = {'size': '10pt', 'font': 'Arial', 'weight': '500', 'color': '#9E7DD5'}\n",
    "kwargs_inconsistent = {'size': '10pt', 'font': 'Arial', 'weight': '500', 'color': '#AF99EF'}\n",
    "kwargs_text8pt = {'size': '7.7pt', 'font': 'Arial'}\n",
    "\n",
    "width = 15.7 * 0.23\n",
    "f = Figure(f\"{width}cm\", \"5.8cm\",\n",
    "\n",
    "    Panel(\n",
    "          SVG(\"../svg/panel_a.svg\").scale(svg_scale).move(0, 0),\n",
    "          Text(\"Ground\", 11, 12.0, **kwargs_text8pt),\n",
    "        Text(\"truth\", 11, 26.0, **kwargs_text8pt),\n",
    "    ).move(-10, 0),\n",
    "    # Panel(\n",
    "    #       SVG(\"../svg/panel_b1.svg\").scale(svg_scale).move(0, 0),\n",
    "    #       Text(\"APT\", 1, 12.0, **kwargs_text8pt),\n",
    "    #       Text(\"5 rounds\", 1, 26.0, **kwargs_text8pt),\n",
    "    # ).move(0, 90),\n",
    "    Panel(\n",
    "          SVG(\"../svg/panel_b1.svg\").scale(svg_scale).move(0, 0),\n",
    "          Text(\"APT\", 11, 12.0, **kwargs_text8pt),\n",
    "    ).move(-10, 75),\n",
    "    Panel(\n",
    "          SVG(\"../svg/panel_c.svg\").scale(svg_scale).move(0, 0),\n",
    "          Text(\"TSNPE\", 11, 12.0, **kwargs_text8pt),\n",
    "    ).move(-10, 150),\n",
    ")\n",
    "\n",
    "f.save(\"../fig/fig6.svg\")\n",
    "svg('../fig/fig6.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04ca8ce1-8c28-4856-ab78-8f20c71dd2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../fig/fig6_20rounds.svg\" / >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from svgutils.compose import *\n",
    "\n",
    "# > Inkscape pixel is 1/90 of an inch, other software usually uses 1/72.\n",
    "# > http://www.inkscapeforum.com/viewtopic.php?f=6&t=5964\n",
    "svg_scale = 1.25  # set this to 1.25 for Inkscape, 1.0 otherwise\n",
    "\n",
    "# Panel letters in Helvetica Neue, 12pt, Medium\n",
    "kwargs_text = {'size': '12pt', 'font': 'Arial', 'weight': '800'}\n",
    "kwargs_consistent = {'size': '10pt', 'font': 'Arial', 'weight': '500', 'color': '#AF99EF'}\n",
    "kwargs_consistent1 = {'size': '10pt', 'font': 'Arial', 'weight': '500', 'color': '#9E7DD5'}\n",
    "kwargs_inconsistent = {'size': '10pt', 'font': 'Arial', 'weight': '500', 'color': '#AF99EF'}\n",
    "kwargs_text8pt = {'size': '7.7pt', 'font': 'Arial'}\n",
    "\n",
    "width = 15.7 * 0.23\n",
    "f = Figure(f\"15.7cm\", \"1.8cm\",\n",
    "    Panel(\n",
    "          SVG(\"../svg/panel_b2.svg\").scale(svg_scale).move(0, 0),\n",
    "          Text(\"APT\", 11, 12.0, **kwargs_text8pt),\n",
    "          Text(\"20 rounds\", 11, 22.0, **kwargs_text8pt),\n",
    "    ).move(-10, 0),\n",
    "\n",
    ")\n",
    "\n",
    "f.save(\"../fig/fig6_20rounds.svg\")\n",
    "svg('../fig/fig6_20rounds.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d1113-c412-4bb3-8d2d-6e0c2bc4355c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
